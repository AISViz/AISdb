{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import aisdb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import cartopy.feature as cfeature\n",
    "from aisdb import DBConn, DBQuery, DomainFromPoints\n",
    "from aisdb.database.dbconn import PostgresDBConn\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "from aisdb.webdata.shore_dist import CoastDist\n",
    "from aisdb.webdata.shore_dist import ShoreDist\n",
    "from aisdb.webdata.shore_dist import PortDist\n",
    "from datetime import datetime, timedelta\n",
    "from aisdb.gis import DomainFromTxts\n",
    "from aisdb.database import sqlfcn_callbacks\n",
    "from shapely import prepare\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "nest_asyncio.apply()\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from aisdb.weather.era5 import ClimateDataStore # for weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# >>> PostgreSQL Information <<<\n",
    "db_user='<user-name>'            # DB User\n",
    "db_dbname='aisviz'         # DB Schema\n",
    "db_password='<password>'    # DB Password\n",
    "db_hostaddr='127.0.0.1'    # DB Host address\n",
    "\n",
    "dbconn = PostgresDBConn(\n",
    "    port=5555,             # PostgreSQL port\n",
    "    user=db_user,          # PostgreSQL username\n",
    "    dbname=db_dbname,      # PostgreSQL database\n",
    "    host=db_hostaddr,      # PostgreSQL address\n",
    "    password=db_password,  # PostgreSQL password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = -70, 45, -58, 53\n",
    "gulf_bbox = [xmin, xmax, ymin, ymax]\n",
    "start_time = datetime(2023, 8, 1)\n",
    "end_time = datetime(2023, 8, 30)\n",
    "\n",
    "qry = DBQuery(\n",
    "    dbconn=dbconn,\n",
    "    start=start_time, end=end_time,\n",
    "    xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax,\n",
    "    callback=aisdb.database.sqlfcn_callbacks.in_time_bbox_validmmsi\n",
    ")\n",
    "\n",
    "ais_tracks = []\n",
    "rowgen = qry.gen_qry()\n",
    "tracks = aisdb.track_gen.TrackGen(rowgen, decimate=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "climate_data_store = ClimateDataStore(['10v','10u'], start_time, end_time,\"/home/CanadaV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the headers for the CSV file\n",
    "headers = ['mmsi', 'time', 'lon', 'lat', 'cog', 'sog',\n",
    "           'utc_second', 'heading', 'rot', 'maneuver','10v','10u','u10','v10']\n",
    "\n",
    "# Open the CSV file for writing\n",
    "csv_filename = '2023-08.csv'\n",
    "\n",
    "# Assuming `climate_data_store.extract_weather()` returns a dictionary\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()  # Write the header once\n",
    "\n",
    "    for track in tracks:\n",
    "        for i in range(len(track['time'])):\n",
    "            # Extract weather data for the current location and time\n",
    "            values = climate_data_store.extract_weather(track['lat'][i], track['lon'][i], track['time'][i])\n",
    "\n",
    "            # Flatten the row\n",
    "            row = {\n",
    "                'rot': track['rot'],\n",
    "                'mmsi': track['mmsi'],\n",
    "                'lon': track['lon'][i],\n",
    "                'lat': track['lat'][i],\n",
    "                'cog': track['cog'][i],\n",
    "                'sog': track['sog'][i],\n",
    "                'time': track['time'][i],\n",
    "                'heading': track['heading'],\n",
    "                'maneuver': track['maneuver'],\n",
    "                'utc_second': track['utc_second'][i],\n",
    "            }\n",
    "\n",
    "            # Add weather data (values) as additional fields in the row\n",
    "            for key, value in values.items():\n",
    "                row[key] = value\n",
    "\n",
    "            # Write the row to the CSV file\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "print(f\"All tracks have been combined and written to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
